(ns ppdsp.masking.two-stage-independent-attack
  (:require [ppdsp.masking.attack-data
             :refer [attack-input-feature-count
                     attack-masked-feature-count
                     closest-known-index-to-unknown]]
            [ppdsp.masking.optimize :refer [nelder-mead-optimize]]
            [ppdsp.masking.utils :refer [combine-logps build-attack-col-matrices]]
            [ppdsp.utils :refer [mean median seq-contains? debug]]
            [ppdsp.utils.random :refer [seeded-rng uniform-random! next-gauss!]]
            [ppdsp.utils.matrices
             :refer [get-matrix-row-map accumulate-rows
                     change-vector-magnitude join-row-wise
                     join-col-wise normalise-to-first-column
                     normalise-to-first-row remove-first-column
                     remove-first-row repeat-block-diagonal
                     matrix->nested-double-array]]
            [clojure.math.numeric-tower :refer [expt]]
            [clojure.core.matrix :as m]
            [clojure.core.matrix.linear :as ml]
            [clojure.core.matrix.stats :as ms])
  (:import [smile.stat.distribution
            GaussianDistribution
            MultivariateGaussianDistribution]))

(defn get-phi-logp
  "Return the log-probability-density for the phi distribution as
  described by Liu et al. (2008). This indicates how likely the masked
  output y is given the input x and a random Gaussian projection."
  [x y]
  ;; We work under the assumption that the unknown record is
  ;; linearly independent from the known records, otherwise it could
  ;; be derived perfectly from the known records. We also assume the
  ;; known records are linearly independent, otherwise they would
  ;; provide redundant information. Column rank is always equal to
  ;; row rank, so rank returns both.
  (if (< (ml/rank x) (m/column-count x))
    ;; If not linearly independent, return negative infinity as a penalty.
    Double/NEGATIVE_INFINITY
    (let [;; k is the number of masked features
          [k record-count] (m/shape y)
          ;; phi has mean zero.
          phi-means-array (double-array (repeat (* k record-count) 0))
          ;; (X^T)X is used as the name in Liu (2007).
          xtx (m/mul
               (*
                ;; Multiplying by 1/k is described in Liu (2007),
                ;; Theorem 5.3.8
                (/ 1 k))
               (m/mmul (m/transpose x) x))
          ;; Creating a block-diagonal matrix is a simpler alternative
          ;; to a Kronecker product with an identity matrix.
          phi-cov (repeat-block-diagonal xtx k)
          phi-cov-array (matrix->nested-double-array phi-cov)]
      ;; Use the MGD from Smile, as the PDF implementation from apache
      ;; math3 will sometimes throw singular-matrix exceptions for
      ;; covariance matrices that are not singular.
      (.logp (MultivariateGaussianDistribution. phi-means-array
                                                phi-cov-array)
             (m/to-double-array y)))))

(defn remove-independent-noise
  "Given the flat list of noise variables from the objective function,
  as well as the masked-cols and independent-sigma, return
  a pair of values: The normalised-masked-cols translated according to
  the independent noise differences, and the log-probability-densities
  that the given noise values would have been generated by a Gaussian
  with the given independent-sigma."
  [noise-variables masked-cols independent-sigma]
  (let [record-count (m/column-count masked-cols)
        ;; The variables represent the independent noise applied to
        ;; each record - a vector of length k for each record.
        noise-differences (-> (m/matrix noise-variables)
                              (m/reshape [record-count
                                          (/ (count noise-variables)
                                             record-count)]))
        ;; Tranpose row-wise noise to be col-wise before
        ;; translation. Force vectorz for efficiency.
        translated-masked-cols (m/sub (m/matrix :vectorz masked-cols)
                                      (m/matrix :vectorz (m/transpose noise-differences)))
        ;; Produce a list of the log-probability-densities of the
        ;; given noise differences.
        noise-logps
        (mapcat
         (fn [noise-diff]
           (map #(.logp (GaussianDistribution. 0 independent-sigma) %) noise-diff))
         (m/rows noise-differences))]
    [translated-masked-cols noise-logps]))

(defn build-rp-objective
  "Build the objective function that will optimize the unknown input and
  independent noise differences between unknown/known records."
  [independent-noise? bias-input-prob? io-attack-data]
  (let [input-feature-count (attack-input-feature-count io-attack-data)
        {:keys [input-cols masked-cols unknown-col-index]} (build-attack-col-matrices io-attack-data)]
    ;; An objective function that simultaneously optimizes the input
    ;; for the unknown record and the independent noise. The score is
    ;; the product of probabilities for the input and independent
    ;; drifts. To prevent underflow to zero when multiplying very
    ;; small probabilities, the logs of probabilities are used (logs
    ;; are added to achieve the same result as multiplying actual
    ;; probabilities).
    (fn [variables]
      (let [unknown-input (take input-feature-count variables)
            unknown-noise (drop input-feature-count variables)
            ;; Set the values for the unknown record's column. To
            ;; eliminate translation (such as that from independent
            ;; noise), both the input and masked records are
            ;; normalised so that the first record is at the
            ;; origin (and therefore it can be removed from
            ;; optimization).
            x (-> input-cols
                  (m/set-column unknown-col-index unknown-input)
                  normalise-to-first-column
                  remove-first-column)
            ;; NOTE: When there is a translation, the masked-cols may be
            ;; slightly different due to floating point rounding errors,
            ;; causing some (usually very minor) differences in the
            ;; masked-cols and therefore y-logp, and therefore final
            ;; attack result.
            y (-> (if independent-noise?
                    (m/set-column masked-cols unknown-col-index
                                  (m/sub (m/get-column masked-cols unknown-col-index)
                                         unknown-noise))
                    masked-cols)
                  normalise-to-first-column
                  remove-first-column)
            ;; Find the probability of point y in distribution
            ;; phi, which is our measure of how likely the given
            ;; combination of input record and independent noise
            ;; would fit with a Gaussian random projection matrix.
            y-logp (try
                     (get-phi-logp x y)
                     (catch IllegalArgumentException ex
                       ;; Catch the exception thrown when the
                       ;; covariance is not positive definite (which
                       ;; may happen when an impossible combination of
                       ;; input record and independent noise is chosen;
                       ;; it is not caused by the translation in the
                       ;; cases tested).
                       (if (= (.getMessage ex) "The matrix is not positive definite.")
                         ;; Return negative infinity as a penalty to
                         ;; this selection.
                         Double/NEGATIVE_INFINITY
                         ;; Otherwise, throw the exception because we
                         ;; don't know what it is.
                         (throw ex))))]
        ;; Combine the final set of logps as the score for the
        ;; objective.
        (if independent-noise?
          (let [independent-sigma (if (= 1 (m/column-count x))
                                    ;; If there is only one known
                                    ;; input (i.e. two input-cols),
                                    ;; then get-best-independent-noise
                                    ;; will return zero noise, and we
                                    ;; must account for the noise on
                                    ;; both the known and unknown
                                    ;; record by doubling the
                                    ;; variance.
                                    (Math/sqrt (* 2 (expt (:independent-sigma io-attack-data) 2)))
                                    (:independent-sigma io-attack-data))
                unknown-noise-dist (GaussianDistribution. 0 independent-sigma)
                noise-logps (map #(.logp unknown-noise-dist %) unknown-noise)]
            (if bias-input-prob?
              (combine-logps [(combine-logps noise-logps) y-logp])
              (combine-logps (conj noise-logps y-logp))))
          (combine-logps [y-logp]))))))

(defn build-independent-noise-objective
  "Build the objective function that will optimize the unknown input and
  independent noise add to records."
  [io-attack-data]
  (let [input-feature-count (attack-input-feature-count io-attack-data)
        input-cols (->> (m/matrix (map :input (:knowns io-attack-data)))
                        (m/transpose)
                        normalise-to-first-column
                        remove-first-column)
        ;; NOTE: When there is a translation, the masked-cols may be
        ;; slightly different due to floating point rounding errors,
        ;; causing some (usually very minor) differences in the
        ;; masked-cols and therefore y-logp, and therefore final
        ;; attack result.
        masked-cols (->> (m/matrix (map :masked (:knowns io-attack-data)))
                         (m/transpose))
        x input-cols]
    ;; An objective function that simultaneously optimizes the input
    ;; for the unknown record and the independent noise added to
    ;; records. The score is the product of probabilities for the
    ;; input and independent noise. To prevent underflow to zero when
    ;; multiplying very small probabilities, the logs of probabilities
    ;; are used (logs are added to achieve the same result as
    ;; multiplying actual probabilities).
    (fn [variables]
      (let [;; Get the y-rows that will be used as input to phi, as
            ;; well as the probabilities of independent noise.
            [y noise-logps]
            (remove-independent-noise variables
                                      masked-cols
                                      (:independent-sigma io-attack-data))
            ;; Normalise y after removing noise.
            y (-> y
                  normalise-to-first-column
                  remove-first-column)
            ;; Find the probability of point y in distribution
            ;; phi, which is our measure of how likely the given
            ;; combination of input record and independent noise
            ;; would fit with a Gaussian random projection matrix.
            y-logp (try
                     (get-phi-logp x y)
                     (catch IllegalArgumentException ex
                       ;; Catch the exception thrown when the
                       ;; covariance is not positive definite (which
                       ;; may happen when an impossible combination of
                       ;; input record and independent noise is chosen;
                       ;; it is not caused by the translation in the
                       ;; cases tested).
                       (if (= (.getMessage ex) "The matrix is not positive definite.")
                         ;; Return negative infinity as a penalty to
                         ;; this selection.
                         Double/NEGATIVE_INFINITY
                         ;; Otherwise, throw the exception because we
                         ;; don't know what it is.
                         (throw ex))))
            final-logps (conj noise-logps y-logp)]
        ;; Combine the final set of logps as the score for the
        ;; objective.
        (combine-logps final-logps)))))

(defn generate-initial-noise-differences!
  "Randomise initial noise according to distributions."
  [io-attack-data rng]
  (let [;; Number of masked features
        k (count (:masked (first (:knowns io-attack-data))))]
    (repeatedly (* k (count (:knowns io-attack-data))) #(next-gauss! rng 0 (:independent-sigma io-attack-data)))))

(defn get-best-independent-noise
  [io-attack-data rng]
  (if (= (count (:knowns io-attack-data)) 1)
    {:optimum (repeat (attack-masked-feature-count io-attack-data) 0)
     :evaluations nil
     :score nil}
    (->>
     (for [_ (range 1)]
       (let [initial-variables (generate-initial-noise-differences! io-attack-data rng)
             objective-fn (build-independent-noise-objective io-attack-data)]
         (nelder-mead-optimize objective-fn initial-variables true)))
     (apply max-key :score))))

(defn remove-independent-noise-attack
  [io-attack-data rng]
  (let [best-noise-attack (get-best-independent-noise io-attack-data rng)
        noise-variables (:optimum best-noise-attack)
        record-count (count (:knowns io-attack-data))
        masked-feature-count (attack-masked-feature-count io-attack-data)
        noise-differences (-> noise-variables
                              (m/matrix)
                              (m/reshape [record-count masked-feature-count]))]
    [(-> io-attack-data
         (assoc :knowns (map (fn [record noise]
                               (assoc record
                                      :masked
                                      (m/sub (:masked record) noise)))
                             (:knowns io-attack-data)
                             (m/rows noise-differences))))
     best-noise-attack]))

(defn generate-initial-guess-vector!
  "Given an rng and the vectors containing a sample of known values for
  each attribute, produce a randomised initial guess for an input."
  [io-attack-data rng]
  (let [known-attribute-vectors (->> (:knowns io-attack-data)
                                     (map :input)
                                     (m/matrix)
                                     (m/columns))
        ;; The method used by Liu (2007) to determine the multivariate
        ;; median is not disclosed, so the median of each attribute is
        ;; taken separately because it is fast and does not bias
        ;; wide-ranging attributes (like the geometric median).
        attribute-medians (map #(median (map m/mget %))
                               known-attribute-vectors)
        attribute-mins (map #(reduce min (map m/mget %))
                            known-attribute-vectors)
        attribute-maxs (map #(reduce max (map m/mget %))
                            known-attribute-vectors)
        ;; Liu (2007) use a guess randomisation range from -2 to 2,
        ;; but the dataset has numeric integer attributes ranging from
        ;; 0-15. We perform randomisation of +/- 50% of each
        ;; attributes range from the known inputs.
        guess-ranges (map #(* 0.5 (- %2 %1)) attribute-mins attribute-maxs)
        guess-offsets (map #(uniform-random! rng (- %) %) guess-ranges)]
    ;; Make an initial guess at the random offsets from the median
    ;; values, as used by Liu (2007).
    (map + attribute-medians guess-offsets)))

(defn reverse-rp
  [independent-noise? bias-input-prob? io-attack-data rng]
  (->>
   (for [_ (range 1)]
     (let [initial-guess (generate-initial-guess-vector! io-attack-data rng)
           initial-variables (if independent-noise?
                               (concat initial-guess
                                       (repeatedly (attack-masked-feature-count io-attack-data)
                                                   #(next-gauss! rng 0 (:independent-sigma io-attack-data))))
                               initial-guess)
           objective-fn (build-rp-objective independent-noise? bias-input-prob? io-attack-data)]
       (nelder-mead-optimize objective-fn initial-variables true)))
   (apply max-key :score)))

(defn known-io-projection-and-independent-noise-map-attack-two-stage
  "Takes the projection-sigma used when producing the Gaussian matrix
  for random projection, the independent-sigma used when adding
  independent noise to each record, a matrix of masked records with a
  matrix of their known input (known records must be linearly
  independent), and an unknown masked record.

  Performs Nelder-Mead maximization to find the most likely input for
  the unknown-masked record using a Maximum A Posteriori attack based
  on the prior knowledge of known input/outputs and the projection and
  independent sigma. We optimize for both the input and the independent
  noises at the same time.

  This is based on the known input/output MAP attack described in:

  K. Liu. Multiplicative Data Perturbation for Privacy Preserving Data
  Mining. PhD thesis, University of Maryland, Baltimore County,
  Baltimore, MD, January 2007 (pages 116-119).

  Liu K., Giannella C., Kargupta H. (2008) A Survey of Attack
  Techniques on Privacy-Preserving Data Perturbation Methods. In:
  Aggarwal C.C., Yu P.S. (eds) Privacy-Preserving Data
  Mining. Advances in Database Systems, vol 34. Springer, Boston,
  MA (pages 371-373)."
  [io-attack-data rng
   & {:keys [optimization-max-evaluations optimization-relative-threshold
             independent-noise? bias-input-prob? only-one-known?]}]
  (let [independent-noise? (if (nil? independent-noise?)
                             ;; Default to accounting for independent
                            ;; noise based on sigma.
                            (> (:independent-sigma io-attack-data) 0)
                            independent-noise?)
        io-attack-data (if (and independent-noise? only-one-known?)
                         (let [known-index-to-keep (closest-known-index-to-unknown io-attack-data)]
                           (update io-attack-data :knowns
                                   (fn [knowns]
                                     (filter #(= (:index %) known-index-to-keep)
                                             knowns))))
                         io-attack-data)
        [rp-io-attack-data best-noise-attack] (if independent-noise?
                                                (remove-independent-noise-attack io-attack-data rng)
                                                [io-attack-data nil])
        masked-feature-count (attack-masked-feature-count io-attack-data)
        record-count (count (:knowns io-attack-data))
        rp-result (reverse-rp independent-noise? bias-input-prob? rp-io-attack-data rng)]
    (assoc rp-result
           :best-noise-attack best-noise-attack)))
