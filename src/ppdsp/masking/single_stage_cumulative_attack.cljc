(ns ppdsp.masking.single-stage-cumulative-attack
  (:require [ppdsp.masking.attack-data
             :refer [attack-input-feature-count
                     attack-masked-feature-count
                     closest-known-index-to-unknown]]
            [ppdsp.masking.optimize :refer [nelder-mead-optimize]]
            [ppdsp.masking.utils :refer [combine-logps build-attack-col-matrices]]
            [ppdsp.utils :refer [mean median seq-contains? debug]]
            [ppdsp.utils.random :refer [seeded-rng uniform-random! next-gauss!]]
            [ppdsp.utils.matrices
             :refer [get-matrix-row-map accumulate-rows
                     change-vector-magnitude join-row-wise
                     join-col-wise normalise-to-first-column
                     normalise-to-first-row remove-first-column
                     remove-first-row repeat-block-diagonal
                     matrix->nested-double-array]]
            [clojure.math.numeric-tower :refer [expt]]
            [clojure.core.matrix :as m]
            [clojure.core.matrix.linear :as ml]
            [clojure.core.matrix.stats :as ms])
  (:import [smile.stat.distribution
            GaussianDistribution
            MultivariateGaussianDistribution]))

(defn get-noise-difference-sigmas
  "Returns the sigmas of the Gaussian distributions of cumulative noise
  differences between all known and unknown records."
  [io-attack-data]
  (let [cumulative-variance (expt (:cumulative-sigma io-attack-data) 2)
        ;; Create a sorted list of all known/unknown record indexes
        record-indexes (sort (conj (map :index (:knowns io-attack-data))
                                   (:index (:unknown io-attack-data))))
        ;; Create a list of the time gaps between records
        index-differences (map #(- %2 %1) record-indexes (rest record-indexes))]
    ;; Sum of gaussians results in a summed variance, so the sigma of
    ;; each noise difference is relative to the index-difference.
    (map #(Math/sqrt (* % cumulative-variance))
         index-differences)))

(defn get-phi-logp
  "Return the log-probability-density for the phi distribution as
  described by Liu et al. (2008). This indicates how likely the masked
  output y is given the input x and a random Gaussian projection
  matrix."
  [x y]
  ;; We work under the assumption that the unknown record is
  ;; linearly independent from the known records, otherwise it could
  ;; be derived perfectly from the known records. We also assume the
  ;; known records are linearly independent, otherwise they would
  ;; provide redundant information. Column rank is always equal to
  ;; row rank, so rank returns both.
  (if (< (ml/rank x) (m/column-count x))
    ;; If not linearly independent, return negative infinity as a penalty.
    Double/NEGATIVE_INFINITY
    (let [;; k is the number of masked features
          [k record-count] (m/shape y)
          ;; phi has mean zero.
          phi-means-array (double-array (repeat (* k record-count) 0))
          ;; (X^T)X is used as the name in Liu (2007).
          xtx (m/mul
               (*
                ;; Multiplying by 1/k is described in Liu (2007),
                ;; Theorem 5.3.8
                (/ 1 k))
               (m/mmul (m/transpose x) x))
          ;; Creating a block-diagonal matrix is a simpler alternative
          ;; to a Kronecker product with an identity matrix.
          phi-cov (repeat-block-diagonal xtx k)
          phi-cov-array (matrix->nested-double-array phi-cov)]
      ;; Use the MGD from Smile, as the PDF implementation from apache
      ;; math3 will sometimes throw singular-matrix exceptions for
      ;; covariance matrices that are not singular.
      (.logp (MultivariateGaussianDistribution. phi-means-array
                                                phi-cov-array)
             (m/to-double-array y)))))

(defn remove-cumulative-noise
  "Given the flat list of noise variables from the objective function,
  as well as the normalised-masked-cols and noise-difference-sigmas,
  return a pair of values: The normalised-masked-cols translated
  according to the accumulated total of the cumulative noise
  differences, and the log-probability-densities that the given noise
  values would have been generated by successive Gaussian noise over
  the gaps between records."
  [noise-variables normalised-masked-cols noise-difference-sigmas]
  (let [record-count (m/column-count normalised-masked-cols)
        ;; The remaining variables represent the cumulative noise
        ;; difference vectors between successive records - a vector of
        ;; length k for each difference between records - one fewer
        ;; than their are records
        noise-differences (-> (m/matrix noise-variables)
                              (m/reshape [record-count
                                          (/ (count noise-variables)
                                             record-count)]))
        ;; The total noise translation for each record can be found by
        ;; accumulating the noise differences between the records.
        cumulative-noise (accumulate-rows noise-differences)
        ;; Tranpose row-wise noise to be col-wise before
        ;; translation. Force vectorz for efficiency.
        translated-masked-cols (m/sub (m/matrix :vectorz normalised-masked-cols)
                                      (m/matrix :vectorz (m/transpose cumulative-noise)))
        ;; Produce a list of the log-probability-densities of the
        ;; given noise differences.
        noise-logps
        (mapcat
         (fn [noise-diff sigma]
           (map #(.logp (GaussianDistribution. 0 sigma) %) noise-diff))
         (m/rows noise-differences)
         noise-difference-sigmas)]
    [translated-masked-cols noise-logps]))

(defn build-known-io-attack-objective
  "Build the objective function that will optimize the unknown input and
  cumulative noise differences between unknown/known records."
  [cumulative-noise? bias-input-prob? io-attack-data]
  (let [input-feature-count (attack-input-feature-count io-attack-data)
        {:keys [input-cols masked-cols unknown-col-index]} (build-attack-col-matrices io-attack-data)
        ;; To eliminate translation (such as that from cumulative
        ;; drift), both the input and masked records are normalised so
        ;; that the first record is at the origin (and therefore it
        ;; can be removed from optimization).
        ;; -----------------------------------------------------------
        ;; NOTE: When there is a translation, the masked-cols may be
        ;; slightly different due to floating point rounding errors,
        ;; causing some (usually very minor) differences in the
        ;; masked-cols and therefore y-logp, and therefore final
        ;; attack result.
        normalised-masked-cols (-> masked-cols
                                   normalise-to-first-column
                                   remove-first-column)
        noise-difference-sigmas (get-noise-difference-sigmas io-attack-data)]
    ;; An objective function that simultaneously optimizes the input
    ;; for the unknown record and the cumulative drifts between the
    ;; unknown/known records. The score is the product of
    ;; probabilities for the input and cumulative drifts. To prevent
    ;; underflow to zero when multiplying very small probabilities,
    ;; the logs of probabilities are used (logs are added to achieve
    ;; the same result as multiplying actual probabilities).
    (fn [variables]
      (let [unknown-input (take input-feature-count variables)
            ;; Set the values for the unknown record's column. To
            ;; eliminate translation (such as that from cumulative
            ;; drift), both the input and masked records are
            ;; normalised so that the first record is at the
            ;; origin (and therefore it can be removed from
            ;; optimization).
            x (-> input-cols
                  (m/set-column unknown-col-index unknown-input)
                  normalise-to-first-column
                  remove-first-column)
            ;; Get the y-rows that will be used as input to phi,
            ;; as well as the probabilities of cumulative noise
            ;; differences.
            [y noise-logps]
            (if cumulative-noise?
              (remove-cumulative-noise (drop input-feature-count variables)
                                       normalised-masked-cols
                                       noise-difference-sigmas)
              ;; We know there is no cumulative noise, so do not
              ;; translate the masked rows and return an empty
              ;; list of noise-probabilities.
              [normalised-masked-cols []])
            ;; Find the probability of point y in distribution
            ;; phi, which is our measure of how likely the given
            ;; combination of input record and cumulative noise
            ;; would fit with a Gaussian random projection matrix.
            y-logp (try
                     (get-phi-logp x y)
                     (catch IllegalArgumentException ex
                       ;; Catch the exception thrown when the
                       ;; covariance is not positive definite (which
                       ;; may happen when an impossible combination of
                       ;; input record and cumulative noise is chosen;
                       ;; it is not caused by the translation in the
                       ;; cases tested).
                       (if (= (.getMessage ex) "The matrix is not positive definite.")
                         ;; Return negative infinity as a penalty to
                         ;; this selection.
                         Double/NEGATIVE_INFINITY
                         ;; Otherwise, throw the exception because we
                         ;; don't know what it is.
                         (throw ex))))
            final-logps (if cumulative-noise?
                          (if bias-input-prob?
                            ;; If biasing the input probability,
                            ;; pre-combine the noise logp to give them
                            ;; a combined equal weight to the y-logp.
                            [(combine-logps noise-logps) y-logp]
                            ;; No bias, combine all logps equally.
                            (conj noise-logps y-logp))
                          ;; If not accounting for cumulative noise,
                          ;; then y-logp is the only input.
                          [y-logp])]
        ;; Combine the final set of logps as the score for the
        ;; objective.
        (combine-logps final-logps)))))

(defn generate-initial-guess-vector!
  "Given an rng and the vectors containing a sample of known values for
  each attribute, produce a randomised initial guess for an input."
  [io-attack-data rng]
  (let [known-attribute-vectors (->> (:knowns io-attack-data)
                                     (map :input)
                                     (m/matrix)
                                     (m/columns))
        ;; The method used by Liu (2007) to determine the multivariate
        ;; median is not disclosed, so the median of each attribute is
        ;; taken separately because it is fast and does not bias
        ;; wide-ranging attributes (like the geometric median).
        attribute-medians (map #(median (map m/mget %))
                               known-attribute-vectors)
        attribute-mins (map #(reduce min (map m/mget %))
                            known-attribute-vectors)
        attribute-maxs (map #(reduce max (map m/mget %))
                            known-attribute-vectors)
        ;; Liu (2007) use a guess randomisation range from -2 to 2,
        ;; but the dataset has numeric integer attributes ranging from
        ;; 0-15. We perform randomisation of +/- 50% of each
        ;; attributes range from the known inputs.
        guess-ranges (map #(* 0.5 (- %2 %1)) attribute-mins attribute-maxs)
        guess-offsets (map #(uniform-random! rng (- %) %) guess-ranges)]
    ;; Make an initial guess at the random offsets from the median
    ;; values, as used by Liu (2007).
    (map + attribute-medians guess-offsets)))

(defn generate-initial-noise-differences!
  "Randomise initial noise according to distributions."
  [io-attack-data rng]
  (let [;; Number of masked features
        k (count (:masked (first (:knowns io-attack-data))))]
    (->> (get-noise-difference-sigmas io-attack-data)
         (mapcat
          (fn [sigma]
            (repeatedly k #(next-gauss! rng 0 sigma)))))))

(defn build-known-io-attack-initial-variables
  [cumulative-noise? io-attack-data rng]
  (let [initial-guess (generate-initial-guess-vector! io-attack-data rng)]
    (if cumulative-noise?
      (concat initial-guess (generate-initial-noise-differences! io-attack-data rng))
      initial-guess)))

(defn known-io-projection-and-cumulative-noise-map-attack-single-stage
  "Takes the projection-sigma used when producing the Gaussian matrix
  for random projection, the cumulative-sigma used when adding
  cumulative noise to each record, a matrix of masked records with a
  matrix of their known input (known records must be linearly
  independent), and an unknown masked record.

  Performs Nelder-Mead maximization to find the most likely input for
  the unknown-masked record using a Maximum A Posteriori attack based
  on the prior knowledge of known input/outputs and the projection and
  cumulative sigmas. We optimize for both the input and the cumulative
  noises at the same time.

  This is based on the known input/output MAP attack described in:

  K. Liu. Multiplicative Data Perturbation for Privacy Preserving Data
  Mining. PhD thesis, University of Maryland, Baltimore County,
  Baltimore, MD, January 2007 (pages 116-119).

  Liu K., Giannella C., Kargupta H. (2008) A Survey of Attack
  Techniques on Privacy-Preserving Data Perturbation Methods. In:
  Aggarwal C.C., Yu P.S. (eds) Privacy-Preserving Data
  Mining. Advances in Database Systems, vol 34. Springer, Boston,
  MA (pages 371-373)."
  [io-attack-data rng
   & {:keys [optimization-max-evaluations optimization-relative-threshold
             cumulative-noise? bias-input-prob? only-one-known?]}]
  (let [bias-input-prob? (if (nil? bias-input-prob?)
                           ;; Default to not biasing the input probability.
                           false
                           bias-input-prob?)
        cumulative-noise? (if (nil? cumulative-noise?)
                            ;; Default to accounting for cumulative
                            ;; noise based on sigma.
                            (> (:cumulative-sigma io-attack-data) 0)
                            cumulative-noise?)
        io-attack-data (if (and cumulative-noise? only-one-known?)
                         (let [known-index-to-keep (closest-known-index-to-unknown io-attack-data)]
                           (update io-attack-data :knowns
                                   (fn [knowns]
                                     (filter #(= (:index %) known-index-to-keep)
                                             knowns))))
                         io-attack-data)
        objective-fn (build-known-io-attack-objective
                      cumulative-noise? bias-input-prob? io-attack-data)
        initial-variables (build-known-io-attack-initial-variables
                           cumulative-noise? io-attack-data rng)]
    ;; Maximize the probability density objective function to find the
    ;; most likely input for the given unknown-masked record.
    (nelder-mead-optimize objective-fn initial-variables true
                          :max-evaluations optimization-max-evaluations
                          :relative-threshold optimization-relative-threshold)))
